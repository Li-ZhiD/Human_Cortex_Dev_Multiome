{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f06e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import sys\n",
    "import os\n",
    "work_dir = \"/path/to/sketched_scenicplus/\"\n",
    "tmp_dir = '/tmp/'\n",
    "os.chdir(work_dir)\n",
    "if not os.path.exists(work_dir):\n",
    "    os.makedirs(work_dir)\n",
    "if not os.path.exists(os.path.join(work_dir, 'scATAC')):\n",
    "    os.makedirs(os.path.join(work_dir, 'scATAC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5742088",
   "metadata": {},
   "outputs": [],
   "source": [
    "## sampling cells by sketching\n",
    "import scanpy as sc\n",
    "from geosketch import gs\n",
    "adata = sc.read_h5ad(\"/path/to/integrated_annotated.h5ad\")\n",
    "adata=adata[~(adata.obs['subclass'].isin(['Unknown',\"Microglia\",'Vascular'])),:]\n",
    "sc.pl.embedding(adata,basis=\"wnn.umap\",color='type',palette=sc.pl.palettes.default_20, frameon=False)\n",
    "\n",
    "N = 10000\n",
    "sketch_index = gs(adata.obsm['pca'], N, replace=False)  \n",
    "adata2=adata[sketch_index,:]\n",
    "cell_data = adata2.obs\n",
    "cell_data['type'] = cell_data['type'].astype(str)\n",
    "cell_data['sample_id']='merge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96428434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyranges as pr\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pickles\n",
    "frag_path=\"/path/to/aggregated_fragment_files/\"  ## manually aggregated fragments\n",
    "files=os.listdir(frag_path)\n",
    "fragments_dict={'merge':os.path.join(frag_path, 'merge_fragment.sort.tsv.gz')}\n",
    "path_to_regions={'merge':os.path.join(frag_path, \"atac_peaks.bed\")}\n",
    "path_to_blacklist= '/path/to/blacklist/hg38-blacklist.v2.bed'\n",
    "\n",
    "target_url='http://hgdownload.cse.ucsc.edu/goldenPath/hg38/bigZips/hg38.chrom.sizes'\n",
    "chromsizes=pd.read_csv(target_url, sep='\\t', header=None)\n",
    "chromsizes.columns=['Chromosome', 'End']\n",
    "chromsizes['Start']=[0]*chromsizes.shape[0]\n",
    "chromsizes=chromsizes.loc[:,['Chromosome', 'Start', 'End']]\n",
    "chromsizes['Chromosome'] = [chromsizes['Chromosome'][x].replace('v', '.') for x in range(len(chromsizes['Chromosome']))]\n",
    "chromsizes['Chromosome'] = [chromsizes['Chromosome'][x].split('_')[1] if len(chromsizes['Chromosome'][x].split('_')) > 1 else chromsizes['Chromosome'][x] for x in range(len(chromsizes['Chromosome']))]\n",
    "chromsizes=pr.PyRanges(chromsizes)\n",
    "\n",
    "## peak call from pseudobulk\n",
    "from pycisTopic.pseudobulk_peak_calling import export_pseudobulk\n",
    "bw_paths, bed_paths = export_pseudobulk(input_data = cell_data,\n",
    "                 variable = 'type',                                                                    \n",
    "                 sample_id_col = 'sample_id',\n",
    "                 chromsizes = chromsizes,\n",
    "                 bed_path = os.path.join(work_dir, 'scATAC/consensus_peak_calling/pseudobulk_bed_files/'),  \n",
    "                 bigwig_path = os.path.join(work_dir, 'scATAC/consensus_peak_calling/pseudobulk_bw_files/'),\n",
    "                 path_to_fragments = fragments_dict,                                                        \n",
    "                 n_cpu = 8,ignore_reinit_error=True,                                                                     \n",
    "                 normalize_bigwig = True,\n",
    "                 remove_duplicates = True,\n",
    "                 _temp_dir = os.path.join(tmp_dir, 'ray_spill'),\n",
    "                 split_pattern = '-')\n",
    "pickle.dump(bed_paths,\n",
    "            open(os.path.join(work_dir, 'scATAC/consensus_peak_calling/pseudobulk_bed_files/bed_paths.pkl'), 'wb'))\n",
    "pickle.dump(bw_paths,\n",
    "           open(os.path.join(work_dir, 'scATAC/consensus_peak_calling/pseudobulk_bed_files/bw_paths.pkl'), 'wb'))\n",
    "bed_paths = pickle.load(open(os.path.join(work_dir, 'scATAC/consensus_peak_calling/pseudobulk_bed_files/bed_paths.pkl'), 'rb'))\n",
    "bw_paths =  pickle.load(open(os.path.join(work_dir, 'scATAC/consensus_peak_calling/pseudobulk_bed_files/bw_paths.pkl'), 'rb'))\n",
    "from pycisTopic.pseudobulk_peak_calling import peak_calling\n",
    "macs_path='macs2'\n",
    "narrow_peaks_dict = peak_calling(macs_path,\n",
    "                                 bed_paths,\n",
    "                                 os.path.join(work_dir, 'scATAC/consensus_peak_calling/MACS/'),\n",
    "                                 genome_size='hs',\n",
    "                                 n_cpu=8,\n",
    "                                 input_format='BEDPE',\n",
    "                                 shift=73,\n",
    "                                 ext_size=146,\n",
    "                                 keep_dup = 'all',\n",
    "                                 q_value = 0.05,\n",
    "                                 _temp_dir = os.path.join(tmp_dir, 'ray_spill'))\n",
    "pickle.dump(narrow_peaks_dict,\n",
    "            open(os.path.join(work_dir, 'scATAC/consensus_peak_calling/MACS/narrow_peaks_dict.pkl'), 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78ab8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Peak annotation\n",
    "\n",
    "from pycisTopic.iterative_peak_calling import *\n",
    "from pycisTopic.qc import *\n",
    "import pybiomart as pbm\n",
    "# Other param\n",
    "peak_half_width = 250\n",
    "consensus_peaks=get_consensus_peaks(narrow_peaks_dict, peak_half_width, chromsizes=chromsizes, path_to_blacklist=path_to_blacklist)\n",
    "consensus_peaks.to_bed(path = os.path.join(work_dir, 'scATAC/consensus_peak_calling/consensus_regions.bed'),keep=True,compression='infer',chain=False)\n",
    "dataset = pbm.Dataset(name='hsapiens_gene_ensembl',  host='http://www.ensembl.org')\n",
    "annot = dataset.query(attributes=['chromosome_name', 'transcription_start_site', 'strand', 'external_gene_name', 'transcript_biotype'])\n",
    "annot['Chromosome/scaffold name'] = annot['Chromosome/scaffold name'].to_numpy(dtype = str)\n",
    "filter = annot['Chromosome/scaffold name'].str.contains('CHR|GL|JH|MT')\n",
    "annot = annot[~filter]\n",
    "annot['Chromosome/scaffold name'] = annot['Chromosome/scaffold name'].str.replace(r'(\\b\\S)', r'chr\\1')\n",
    "annot.columns=['Chromosome', 'Start', 'Strand', 'Gene', 'Transcript_type']\n",
    "annot = annot[annot.Transcript_type == 'protein_coding']\n",
    "\n",
    "metadata_bc, profile_data_dict = compute_qc_stats(\n",
    "                fragments_dict = fragments_dict,\n",
    "                tss_annotation = annot,\n",
    "                stats=['barcode_rank_plot', 'duplicate_rate', 'insert_size_distribution', 'profile_tss', 'frip'],\n",
    "                label_list = None,\n",
    "                path_to_regions = path_to_regions,\n",
    "                n_cpu = 1,\n",
    "                valid_bc = None,\n",
    "                n_frag = 100,\n",
    "                n_bc = None,\n",
    "                tss_flank_window = 1000,\n",
    "                tss_window = 50,\n",
    "                tss_minimum_signal_window = 100,\n",
    "                tss_rolling_window = 10,\n",
    "                remove_duplicates = True,\n",
    "                _temp_dir = os.path.join(tmp_dir + 'ray_spill'))\n",
    "\n",
    "if not os.path.exists(os.path.join(work_dir, 'scATAC/quality_control')):\n",
    "    os.makedirs(os.path.join(work_dir, 'scATAC/quality_control'))\n",
    "pickle.dump(metadata_bc,\n",
    "            open(os.path.join(work_dir, 'scATAC/quality_control/metadata_bc.pkl'), 'wb'))\n",
    "pickle.dump(profile_data_dict,\n",
    "            open(os.path.join(work_dir, 'scATAC/quality_control/profile_data_dict.pkl'), 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfd118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Quality check\n",
    "key='merge'\n",
    "QC_filters = {\n",
    "    'Log_unique_nr_frag': [3.3 , None],\n",
    "    'FRIP':               [0.45, None],\n",
    "    'TSS_enrichment':     [5   , None],\n",
    "    'Dupl_rate':          [None, None]\n",
    "\n",
    "}\n",
    "\n",
    "# Return figure to plot together with other metrics, and cells passing filters. Figure will be saved as pdf.\n",
    "from pycisTopic.qc import *\n",
    "FRIP_NR_FRAG_fig, FRIP_NR_FRAG_filter=plot_barcode_metrics(metadata_bc[key],\n",
    "                                       var_x='Log_unique_nr_frag',\n",
    "                                       var_y='FRIP',\n",
    "                                       min_x=QC_filters['Log_unique_nr_frag'][0],\n",
    "                                       max_x=QC_filters['Log_unique_nr_frag'][1],\n",
    "                                       min_y=QC_filters['FRIP'][0],\n",
    "                                       max_y=QC_filters['FRIP'][1],\n",
    "                                       return_cells=True,\n",
    "                                       return_fig=True,\n",
    "                                       plot=False)\n",
    "# Return figure to plot together with other metrics, and cells passing filters\n",
    "TSS_NR_FRAG_fig, TSS_NR_FRAG_filter=plot_barcode_metrics(metadata_bc[key],\n",
    "                                      var_x='Log_unique_nr_frag',\n",
    "                                      var_y='TSS_enrichment',\n",
    "                                      min_x=QC_filters['Log_unique_nr_frag'][0],\n",
    "                                      max_x=QC_filters['Log_unique_nr_frag'][1],\n",
    "                                      min_y=QC_filters['TSS_enrichment'][0],\n",
    "                                      max_y=QC_filters['TSS_enrichment'][1],\n",
    "                                      return_cells=True,\n",
    "                                      return_fig=True,\n",
    "                                      plot=False)\n",
    "# Return figure to plot together with other metrics, but not returning cells (no filter applied for the duplication rate  per barcode)\n",
    "DR_NR_FRAG_fig=plot_barcode_metrics(metadata_bc[key],\n",
    "                                      var_x='Log_unique_nr_frag',\n",
    "                                      var_y='Dupl_rate',\n",
    "                                      min_x=QC_filters['Log_unique_nr_frag'][0],\n",
    "                                      max_x=QC_filters['Log_unique_nr_frag'][1],\n",
    "                                      min_y=QC_filters['Dupl_rate'][0],\n",
    "                                      max_y=QC_filters['Dupl_rate'][1],\n",
    "                                      return_cells=False,\n",
    "                                      return_fig=True,\n",
    "                                      plot=False,\n",
    "                                      plot_as_hexbin = True)\n",
    "\n",
    "# Plot barcode stats in one figure\n",
    "fig=plt.figure(figsize=(10,10))\n",
    "plt.subplot(1, 3, 1)\n",
    "img = fig2img(FRIP_NR_FRAG_fig)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 2)\n",
    "img = fig2img(TSS_NR_FRAG_fig)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 3)\n",
    "img = fig2img(DR_NR_FRAG_fig)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "bc_passing_filters = {'merge':[]}\n",
    "bc_passing_filters['merge'] = list((set(FRIP_NR_FRAG_filter) & set(TSS_NR_FRAG_filter)))\n",
    "pickle.dump(bc_passing_filters,\n",
    "            open(os.path.join(work_dir, 'scATAC/quality_control/bc_passing_filters.pkl'), 'wb'))\n",
    "print(f\"{len(bc_passing_filters['merge'])} barcodes passed QC stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a844ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create and run pycisTopic wrapper\n",
    "from pycisTopic.cistopic_class import *\n",
    "key='merge'\n",
    "cistopic_obj = create_cistopic_object_from_fragments(\n",
    "                            path_to_fragments=fragments_dict[key],\n",
    "                            path_to_regions=path_to_regions[key],\n",
    "                            path_to_blacklist=path_to_blacklist,\n",
    "                            metrics=metadata_bc[key],\n",
    "                            valid_bc=list(cell_data.index),\n",
    "                            n_cpu=1,\n",
    "                            project=key)\n",
    "cistopic_obj.add_cell_data(cell_data)\n",
    "pickle.dump(cistopic_obj,\n",
    "            open(os.path.join(work_dir, 'scATAC/sketched_cistopic_obj.pkl'), 'wb'))\n",
    "\n",
    "from pycisTopic.cistopic_class import *\n",
    "models=run_cgs_models(cistopic_obj,\n",
    "                    n_topics=[2,4,10,16,32,48,64],\n",
    "                    n_cpu=5,\n",
    "                    n_iter=500,\n",
    "                    random_state=555,\n",
    "                    alpha=50,\n",
    "                    alpha_by_topic=True,\n",
    "                    eta=0.1,\n",
    "                    eta_by_topic=False,\n",
    "                    save_path=None,\n",
    "                    _temp_dir = os.path.join(tmp_dir + 'ray_spill'),ignore_reinit_error=True)\n",
    "if not os.path.exists(os.path.join(work_dir, 'scATAC/models')):\n",
    "    os.makedirs(os.path.join(work_dir, 'scATAC/models'))\n",
    "\n",
    "pickle.dump(models,open(os.path.join(work_dir, 'scATAC/models/models_500_iter_LDA.pkl'), 'wb'))\n",
    "model = evaluate_models(models,select_model=64,return_model=True,metrics=['Arun_2010','Cao_Juan_2009', 'Minmo_2011', 'loglikelihood'],\n",
    "                        plot_metrics=False)\n",
    "\n",
    "from pycisTopic.clust_vis import *\n",
    "run_umap(cistopic_obj, target  = 'cell', scale=True)\n",
    "plot_metadata(cistopic_obj, reduction_name = 'UMAP', variables = ['type'])\n",
    "plot_topic(cistopic_obj, reduction_name = 'UMAP', num_columns = 4)\n",
    "\n",
    "\n",
    "from pycisTopic.topic_binarization import *\n",
    "region_bin_topics_otsu = binarize_topics(cistopic_obj, method='otsu')\n",
    "region_bin_topics_top3k = binarize_topics(cistopic_obj, method='ntop', ntop = 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f073c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalization\n",
    "from pycisTopic.diff_features import *\n",
    "imputed_acc_obj = impute_accessibility(cistopic_obj, selected_cells=None, selected_regions=None, scale_factor=10**6)\n",
    "normalized_imputed_acc_obj = normalize_scores(imputed_acc_obj, scale_factor=10**4)\n",
    "variable_regions = find_highly_variable_features(normalized_imputed_acc_obj, plot = False)\n",
    "markers_dict = find_diff_features(cistopic_obj, imputed_acc_obj, variable='type', var_features=variable_regions, split_pattern = '-')\n",
    "\n",
    "if not os.path.exists(os.path.join(work_dir, 'scATAC/candidate_enhancers')):\n",
    "    os.makedirs(os.path.join(work_dir, 'scATAC/candidate_enhancers'))\n",
    "pickle.dump(region_bin_topics_otsu, open(os.path.join(work_dir, 'scATAC/candidate_enhancers/region_bin_topics_otsu.pkl'), 'wb'))\n",
    "pickle.dump(region_bin_topics_top3k, open(os.path.join(work_dir, 'scATAC/candidate_enhancers/region_bin_topics_top3k.pkl'), 'wb'))\n",
    "pickle.dump(markers_dict, open(os.path.join(work_dir, 'scATAC/candidate_enhancers/markers_dict.pkl'), 'wb'))\n",
    "\n",
    "##Convert to dictionary of pyranges objects.\n",
    "import pyranges as pr\n",
    "from pycistarget.utils import region_names_to_coordinates\n",
    "region_sets = {}\n",
    "region_sets['topics_otsu'] = {}\n",
    "region_sets['topics_top_3'] = {}\n",
    "region_sets['DARs'] = {}\n",
    "for topic in region_bin_topics_otsu.keys():\n",
    "    regions = region_bin_topics_otsu[topic].index[region_bin_topics_otsu[topic].index.str.startswith('chr')] #only keep regions on known chromosomes\n",
    "    region_sets['topics_otsu'][topic] = pr.PyRanges(region_names_to_coordinates(regions))\n",
    "for topic in region_bin_topics_top3k.keys():\n",
    "    regions = region_bin_topics_top3k[topic].index[region_bin_topics_top3k[topic].index.str.startswith('chr')] #only keep regions on known chromosomes\n",
    "    region_sets['topics_top_3'][topic] = pr.PyRanges(region_names_to_coordinates(regions))\n",
    "for DAR in markers_dict.keys():\n",
    "    if not markers_dict[DAR].empty:\n",
    "        regions = markers_dict[DAR].index[markers_dict[DAR].index.str.startswith('chr')] #only keep regions on known chromosomes\n",
    "        region_sets['DARs'][DAR] = pr.PyRanges(region_names_to_coordinates(regions))\n",
    "for key in region_sets.keys():\n",
    "    print(f'{key}: {region_sets[key].keys()}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba68818",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run wrapper of cistarget\n",
    "from scenicplus.wrappers.run_pycistarget import run_pycistarget\n",
    "db_fpath = \"/path/to/cistarget_database/\"\n",
    "motif_annot_fpath = \"/path/to/cistarget_database/\"\n",
    "rankings_db = os.path.join(db_fpath, 'hg38_screen_v10_clust.regions_vs_motifs.rankings.feather')\n",
    "scores_db =  os.path.join(db_fpath, 'hg38_screen_v10_clust.regions_vs_motifs.scores.feather')\n",
    "motif_annotation = os.path.join(motif_annot_fpath, 'motifs-v10-nr.hgnc-m0.00001-o0.0.tbl')\n",
    "\n",
    "\n",
    "run_pycistarget(\n",
    "    region_sets = region_sets,\n",
    "    species = 'homo_sapiens',\n",
    "    save_path = os.path.join(work_dir, 'motifs'),\n",
    "    ctx_db_path = rankings_db,\n",
    "    dem_db_path = scores_db,\n",
    "    path_to_motif_annotations = motif_annotation,\n",
    "    run_without_promoters = True,\n",
    "    n_cpu = 2,\n",
    "    _temp_dir = os.path.join(tmp_dir, 'ray_spill'),\n",
    "    annotation_version = 'v10nr_clust',)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822837f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create and run scenicplus wrapper\n",
    "from scenicplus.scenicplus_class import create_SCENICPLUS_object\n",
    "from scenicplus.wrappers.run_scenicplus import run_scenicplus\n",
    "import numpy as np\n",
    "import dill\n",
    "import pybiomart as pbm\n",
    "\n",
    "menr = dill.load(open(os.path.join(work_dir, 'motifs/menr.pkl'), 'rb'))\n",
    "scplus_obj = create_SCENICPLUS_object(\n",
    "    GEX_anndata = adata,\n",
    "    cisTopic_obj = cistopic_obj,\n",
    "    menr = menr,\n",
    "    bc_transform_func = lambda x: f'{x}___merge' )\n",
    "\n",
    "scplus_obj.X_EXP = np.array(scplus_obj.X_EXP.todense())\n",
    "\n",
    "ensembl_version_dict = {'105': 'http://www.ensembl.org',\n",
    "                        '104': 'http://may2021.archive.ensembl.org/',\n",
    "                        '103': 'http://feb2021.archive.ensembl.org/',\n",
    "                        '102': 'http://nov2020.archive.ensembl.org/',\n",
    "                        '101': 'http://aug2020.archive.ensembl.org/',\n",
    "                        '100': 'http://apr2020.archive.ensembl.org/',\n",
    "                        '99': 'http://jan2020.archive.ensembl.org/',\n",
    "                        '98': 'http://sep2019.archive.ensembl.org/',\n",
    "                        '97': 'http://jul2019.archive.ensembl.org/',\n",
    "                        '96': 'http://apr2019.archive.ensembl.org/',\n",
    "                        '95': 'http://jan2019.archive.ensembl.org/',\n",
    "                        '94': 'http://oct2018.archive.ensembl.org/',\n",
    "                        '93': 'http://jul2018.archive.ensembl.org/',\n",
    "                        '92': 'http://apr2018.archive.ensembl.org/',\n",
    "                        '91': 'http://dec2017.archive.ensembl.org/',\n",
    "                        '90': 'http://aug2017.archive.ensembl.org/',\n",
    "                        '89': 'http://may2017.archive.ensembl.org/',\n",
    "                        '88': 'http://mar2017.archive.ensembl.org/',\n",
    "                        '87': 'http://dec2016.archive.ensembl.org/',\n",
    "                        '86': 'http://oct2016.archive.ensembl.org/',\n",
    "                        '80': 'http://may2015.archive.ensembl.org/',\n",
    "                        '77': 'http://oct2014.archive.ensembl.org/',\n",
    "                        '75': 'http://feb2014.archive.ensembl.org/',\n",
    "                        '54': 'http://may2009.archive.ensembl.org/'}\n",
    "\n",
    "\n",
    "def test_ensembl_host(scplus_obj, host, species):\n",
    "    dataset = pbm.Dataset(name=species+'_gene_ensembl',  host=host)\n",
    "    annot = dataset.query(attributes=['chromosome_name', 'transcription_start_site', 'strand', 'external_gene_name', 'transcript_biotype'])\n",
    "    annot.columns = ['Chromosome', 'Start', 'Strand', 'Gene', 'Transcript_type']\n",
    "    annot['Chromosome'] = annot['Chromosome'].astype('str')\n",
    "    filter = annot['Chromosome'].str.contains('CHR|GL|JH|MT')\n",
    "    annot = annot[~filter]\n",
    "    annot.columns=['Chromosome', 'Start', 'Strand', 'Gene', 'Transcript_type']\n",
    "    gene_names_release = set(annot['Gene'].tolist())\n",
    "    ov=len([x for x in scplus_obj.gene_names if x in gene_names_release])\n",
    "    print('Genes recovered: ' + str(ov) + ' out of ' + str(len(scplus_obj.gene_names)))\n",
    "    return ov\n",
    "\n",
    "n_overlap = {}\n",
    "for version in ensembl_version_dict.keys():\n",
    "    print(f'host: {version}')\n",
    "    try:\n",
    "        n_overlap[version] =  test_ensembl_host(scplus_obj, ensembl_version_dict[version], 'hsapiens')\n",
    "    except:\n",
    "        print('Host not reachable')\n",
    "v = sorted(n_overlap.items(), key=lambda item: item[1], reverse=True)[0][0]\n",
    "print(f\"version: {v} has the largest overlap, use {ensembl_version_dict[v]} as biomart host\")\n",
    "biomart_host = \"http://sep2019.archive.ensembl.org/\"\n",
    "\n",
    "scplus_obj.dr_cell['GEX_X_pca'] = scplus_obj.dr_cell['GEX_pca'].iloc[:, 0:2]\n",
    "scplus_obj.dr_cell['GEX_rep'] = scplus_obj.dr_cell['GEX_wnn.umap'].iloc[:, 0:2]\n",
    "\n",
    "try:\n",
    "    run_scenicplus(\n",
    "        scplus_obj = scplus_obj,\n",
    "        variable = ['ACC_type'],\n",
    "        species = 'hsapiens',\n",
    "        assembly = 'hg38',\n",
    "        tf_file = '/path/to/utoronto_human_tfs_v_1.01.txt',\n",
    "        save_path = os.path.join(work_dir, 'scenicplus'),\n",
    "        biomart_host = biomart_host,\n",
    "        upstream = [1000, 150000],\n",
    "        downstream = [1000, 150000],\n",
    "        calculate_TF_eGRN_correlation = True,\n",
    "        calculate_DEGs_DARs = True,\n",
    "        export_to_loom_file = True,\n",
    "        export_to_UCSC_file = True,\n",
    "        path_bedToBigBed = '/path/to/ucsc_bedToBigBed/',\n",
    "        n_cpu = 4,\n",
    "        _temp_dir = os.path.join(tmp_dir, 'ray_spill'))\n",
    "except Exception as e:\n",
    "    #in case of failure, still save the object\n",
    "    dill.dump(scplus_obj, open(os.path.join(work_dir, '/sketched_scplus_obj.pkl'), 'wb'), protocol=-1)\n",
    "    raise(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d7f87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## data filtering\n",
    "from scenicplus.preprocessing.filtering import apply_std_filtering_to_eRegulons\n",
    "apply_std_filtering_to_eRegulons(scplus_obj)\n",
    "from scenicplus.eregulon_enrichment import score_eRegulons\n",
    "region_ranking = dill.load(open(os.path.join(work_dir, 'scenicplus//region_ranking.pkl'), 'rb')) #load ranking calculated using the wrapper function\n",
    "gene_ranking = dill.load(open(os.path.join(work_dir, 'scenicplus//gene_ranking.pkl'), 'rb')) #load ranking calculated using the wrapper function\n",
    "score_eRegulons(scplus_obj,\n",
    "                ranking = region_ranking,\n",
    "                eRegulon_signatures_key = 'eRegulon_signatures_filtered',\n",
    "                key_added = 'eRegulon_AUC_filtered',\n",
    "                enrichment_type= 'region',\n",
    "                auc_threshold = 0.05,\n",
    "                normalize = False,\n",
    "                n_cpu = 5)\n",
    "score_eRegulons(scplus_obj,\n",
    "                gene_ranking,\n",
    "                eRegulon_signatures_key = 'eRegulon_signatures_filtered',\n",
    "                key_added = 'eRegulon_AUC_filtered',\n",
    "                enrichment_type = 'gene',\n",
    "                auc_threshold = 0.05,\n",
    "                normalize= False,\n",
    "                n_cpu = 5)\n",
    "\n",
    "from scenicplus.cistromes import TF_cistrome_correlation, generate_pseudobulks\n",
    "\n",
    "generate_pseudobulks(\n",
    "        scplus_obj = scplus_obj,\n",
    "        variable = 'ACC_type',\n",
    "        auc_key = 'eRegulon_AUC_filtered',nr_cells=4,\n",
    "        signature_key = 'Gene_based')\n",
    "generate_pseudobulks(\n",
    "        scplus_obj = scplus_obj,\n",
    "        variable = 'ACC_type',\n",
    "        auc_key = 'eRegulon_AUC_filtered',nr_cells=4,\n",
    "        signature_key = 'Region_based')\n",
    "\n",
    "TF_cistrome_correlation(\n",
    "            scplus_obj,\n",
    "            use_pseudobulk = True,\n",
    "            variable = 'ACC_type',\n",
    "            auc_key = 'eRegulon_AUC_filtered',\n",
    "            signature_key = 'Gene_based',\n",
    "            out_key = 'filtered_gene_based')\n",
    "TF_cistrome_correlation(\n",
    "            scplus_obj,\n",
    "            use_pseudobulk = True,\n",
    "            variable = 'ACC_type',\n",
    "            auc_key = 'eRegulon_AUC_filtered',\n",
    "            signature_key = 'Region_based',\n",
    "            out_key = 'filtered_region_based')\n",
    "##correlation test\n",
    "from scenicplus.eregulon_enrichment import *\n",
    "get_eRegulons_as_signatures(scplus_obj, eRegulon_metadata_key='eRegulon_metadata', key_added='eRegulon_signatures')\n",
    "\n",
    "df1 = scplus_obj.uns['eRegulon_AUC']['Gene_based'].copy()\n",
    "df2 = scplus_obj.uns['eRegulon_AUC']['Region_based'].copy()\n",
    "df1.columns = [x.split('_(')[0] for x in df1.columns]\n",
    "df2.columns = [x.split('_(')[0] for x in df2.columns]\n",
    "correlations = df1.corrwith(df2, axis = 0)\n",
    "correlations = correlations[abs(correlations) > 0.0]\n",
    "keep = [x for x in correlations.index if '+_+' in x] + [x for x in correlations.index if '-_+' in x]\n",
    "keep = direct + keep_extended\n",
    "keep_gene = [x for x in scplus_obj.uns['eRegulon_AUC']['Gene_based'].columns if x.split('_(')[0] in keep]\n",
    "keep_all = [x.split('_(')[0] for x in keep_gene]\n",
    "keep_region = [x for x in scplus_obj.uns['eRegulon_AUC']['Region_based'].columns if x.split('_(')[0] in keep]\n",
    "scplus_obj.uns['selected_eRegulons'] = {}\n",
    "scplus_obj.uns['selected_eRegulons']['Gene_based'] = keep_gene\n",
    "scplus_obj.uns['selected_eRegulons']['Region_based'] = keep_region\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fec282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Regulon specificity calculation\n",
    "from scenicplus.RSS import *\n",
    "binarize_AUC(scplus_obj,\n",
    "             auc_key='eRegulon_AUC',\n",
    "             out_key='eRegulon_AUC_thresholds',\n",
    "             signature_keys=['Gene_based', 'Region_based'],\n",
    "             n_cpu=3)\n",
    "regulon_specificity_scores(scplus_obj,\n",
    "                         'ACC_type',\n",
    "                         signature_keys=['Region_based'],\n",
    "                         selected_regulons=scplus_obj.uns['selected_eRegulon']['Region_based'],\n",
    "                         out_key_suffix='_region_based',\n",
    "                         scale=False)\n",
    "regulon_specificity_scores(scplus_obj,\n",
    "                         'ACC_type',\n",
    "                         signature_keys=['Gene_based'],\n",
    "                         selected_regulons=scplus_obj.uns['selected_eRegulon']['Gene_based'],\n",
    "                         out_key_suffix='_gene_based',\n",
    "                         scale=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
